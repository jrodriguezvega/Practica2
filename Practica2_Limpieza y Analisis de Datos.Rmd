---
title: 'Practica 2: Limpieza y análisis de datos'
author: 'Juan Rodríguez Vega, Alejandro Gallardo Alberola'
date: "Enero 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PEC-header.html
      after_body: PEC-header.html
  word_document: default
  pdf_train_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```


******
# Enunciado
******

El objetivo de esta actividad será el tratamiento de un dataset, que puede ser el creado en la práctica 1 o bien cualquier dataset libre disponible en Kaggle (<https://www.kaggle.com>).

Algunos ejemplos de dataset con los que podéis trabajar son:

- Red Wine Quality (<https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009>)

- Titanic: Machine Learning from Disaster (<https://www.kaggle.com/c/titanic>)

El último ejemplo corresponde a una competición activa de Kaggle de manera que, opcionalmente, podéis aprovechar el trabajo realizado durante la práctica para entrar en esta competición.

Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:

1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

2. Integración y selección de los datos de interés a analizar.

3. Limpieza de los datos.

  3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?
  
  3.2. Identificación y tratamiento de valores extremos.
  
4. Análisis de los datos.

  4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).
  
  4.2. Comprobación de la normalidad y homogeneidad de la varianza.
  
  4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis,correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

5. Representación de los resultados a partir de tablas y gráficas.

6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?


******
# Solución
******

## Descripción del dataset

El RMS Titanic fue un transatlántico británico, el mayor barco de pasajeros del mundo al finalizar su construcción, que se hundió durante la noche del 14 y la madrugada del 15 de abril de 1912 durante su viaje inaugural desde Southampton a Nueva York. En el hundimiento del Titanic murieron 1496 personas de las 2208 que iban a bordo, lo que convierte a esta catástrofe en uno de los mayores naufragios de la historia ocurridos en tiempo de paz. Construido entre 1909 y 1912 en los astilleros de Harland & Wolff en Belfast, el Titanic era el segundo de los tres buques que formaban la clase Olympic, propiedad de la naviera White Star Line, junto al RMS Olympic y, posteriormente, el HMHS Britannic (Wikipedia).

El conjunto de datos está dividido en dos conjuntos de datos:

- ***train.csv***: conjunto de pasajeros para elaborar los modelos de aprendizaje. Ya están clasificados (o sobrevivieron o murieron).

- ***test.csv***: conjunto de pasajeros no clasificados para aplicar la predicción de los modelos.

Es importante señalar que el dataset no contiene los datos de todos los pasajeros del barco. El dataset de entrenamiento únicamente contiene 891 registros con 12 variables:

- ***PassengerID***: ID unívoco del pasajero

- ***Survived***: el pasajero sobrevive o no (0 = No, 1 = Yes)

- ***Pclass***: Clase del billete (1 = 1st, 2 = 2nd, 3 = 3rd)

- ***Name***: Nombre del pasajero

- ***Sex***: Género del pasajero ("male" o "female")

- ***Age***: Edad del pasajero

- ***AibSp***: nº de hermanos/cónyuges del pasajero abordo del barco

- ***Parch***: nº de padres/hijos del pasajero abordo del barco

- ***Ticket***: nº de billete del pasajero

- ***Fare***: Tarifa del pasajero

- ***Ticket***: nº de billete del pasajero

- ***Cabin***: nº de cabina del pasajero

- ***Embarked***: Puerto de embarque del pasajero (C = Cherbourg, Q = Queenstown, S = Southampton)

A partir de este conjunto de datos se pretende dar respuesta a muchas de las cuestiones que siempre han rodeado a la supervencia de los pasajeros del Titanic. De esta forma, se puede ver qué condiciones (variables) influyeron principalmente a la hora de que una persona sobreviese o no. Por ejemplo:

- ¿Se priorizó a los pasajeros de primera clase sobre el resto?

- ¿Fueron las mujeres y los niños los primeros que embarcaron en los botes salvavidas?

- ¿Qué tipos de pasajero tuvieron más probabilidades de sobrevivir?

- ¿Qué tipo de pasajero procedía de cada punto de embarque?

- Etc.

## Integración y selección de los datos

En este apartado se procede a cargar el dataset *train* y *test*, ya que sobre el primero se construyen los modelos y sobre el segundo se realiza la fase de test.

A continuación, se muestran algunos registros e información general de los datos que servirá para posteriormente proceder a la limpieza a adaptación de los datos.

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Carga de librerías
library(psych)
library(Hmisc)
library(psych)
library(corrplot)
library(gridExtra)
library(C50)


# Carga de los datasets
df_train <- read.csv("train.csv", header=T, sep=",")
df_test <- read.csv("test.csv", header=T, sep=",")

# Visualización de algunos registros del dataset
head(df_train,5)
tail(df_train,5)

# Datos estadísticos básicos
summary(df_train)

# Estructura y tipo de los datos
str(df_train)
```

## Limpieza de los datos

### Análisis de valores vacíos y/o nulos

En primer lugar se realiza un análisis de los valores nulos o vacíos y, posteriormente, se procede a eliminar variables con poco valor significativo para el análisis de datos.

*Nota*: Estos valores están representados en el dataset por NA o "". No aparecen otros típicos como " " o "?".

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Análisis de valores nulos o vacíos
colMeans(is.na(df_train))
colMeans(df_train =="")
```

Tal y como se puede comprobar, la variable *Cabin* posee un 77% de valores nulos o vacíos. Por tanto, se procede a prescindir de dicha variable ya que no tiene sentido inferir tal elevada cantidad de valores. 

Por otro lado, la variable *Age* posee casi un 20% de valores nulos; en este caso concreto, si bien es una cifra considerable, la significancia de este atributo puede ser relevante y, por tanto, se mantiene. En un análisis posterior, se determinará si se infieren estos valores o no y ver cómo afecta a los distintos estadísticos. Por ejemplo, una opción podría ser sustituir los valores por la media/mediana en tanto que exista un comportamiento de normalidad.

Por último, se observa que la variable *Embarked* posee un 0.2% de valores nulos. En este sentido, al tratarse de una variable cualitativa, se procede a inferir dichos valores con el valor más representado.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se eliminan las variables Name, Ticket y Cabin
df_train <- df_train[,-c(4, 9, 11)]

# Inferencia de valores nulos más representativo (S - Southampton)
table(df_train$Embarked)
df_train$Embarked <- replace(df_train$Embarked, which((df_train$Embarked =="")), 'S')
```

### Conversión y adaptación de los datos

Además de suprimir la variable ***Cabin***, se eliminan del conjunto de datos las variables ***name*** y ***Ticket*** puesto que son identificativos unívocos que no aportan valor y cuya funcionalidad ya viene dada por la variable ***PassengerID***.

Por último, se procede a adaptar los datos para facilitar su posterior análisis y realizando la conversión de tipos de algunas variables.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Factorización
df_train$Survived <- factor(df_train$Survived, levels = c(0,1), labels= c("No", "Yes"))
df_train$Pclass <- factor(df_train$Pclass, levels = c(1,2,3), labels= c("1st", "2nd", "3rd"))
df_train$Sex <- factor(df_train$Sex, levels= c("female", "male"), labels = c("Female", "Male"))
df_train$Embarked <- factor(df_train$Embarked, levels= c("C","Q","S"), labels = c("Cherbourg","Queenstown", "Southampton"))


# Se guarda el dataframe original con la adaptación de datos
df_original <- df_train

```

### Análisis de valores extremos

A continuación, se procede a visualizar y analizar los posibles *outliers* asociados a las variables contínuas.

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Index. de variables cuantitativas
v_var_cuant <- c(5:8)

# Estadísticas de valores nulos o vacíos
par(mfrow=c(1,4))
for(i in v_var_cuant){
   boxplot(df_train[,i], main=colnames(df_train)[i])
}
```

Es importante considerar que estas observaciones pueden afectar a los estadísticos y, por tanto, hacer análisis sesgado de los datos (por ejemplo, incrementan significativamente el error en la varianza de los datos). Se puede observar algunas muestras fuera de lo común, si bien, no parecen cifras muy desproporcionadas. Por tanto, se tendrán en cuenta para un primer análisis.

*Nota:* En análisis posteriores es interesante ver cómo afectan estos datos a los estadísticos y tomar otro tipo de decisiones sobre qué hacer con estos.

## Análisis de datos

### Medidas de dispersión

Se analizan otros estadísticos como la varianza o la desviación estándar y se aplica el test de Shapiro-Wilk para comprobar la normalidad de las variables a través de contraste de hipótesis y, a partir del cual, si el p-value es menor al nivel de significancia (0.05), se rechaza la hipótesis nula (distribución normal). 


```{r echo=TRUE, message=FALSE, warning=FALSE}
v_var <- vector(length = length(v_var_cuant))
v_sd <- vector(length = length(v_var_cuant))
v_pvalue_shapiro <- vector(length = length(v_var_cuant))
for (i in seq_along(v_var_cuant)){
  v_var[i] <- var(df_train[,v_var_cuant[i]],na.rm = TRUE)
  v_sd[i] <- sd(df_train[,v_var_cuant[i]] ,na.rm = TRUE)
  v_pvalue_shapiro[i] <- as.double(shapiro.test(df_train[,v_var_cuant[i]])["p.value"])
}
medidas_dispersion_shap <- data.frame(colnames(df_train[,v_var_cuant]),round(v_var,4), round(v_sd,4), round(v_pvalue_shapiro,4))

colnames(medidas_dispersion_shap) <- c("attr", "varianza", "desviación estándar", "shapiro p-value")
medidas_dispersion_shap
```


Por tanto, se puede concluir que las variables no atienden a una distribución normal. A continuación, se muestra la distribución de las variables en comparación con la normal donde se verifica lo anteriormente expuesto. Además, se muestra un Q-Q plot para comprobar si los cuantiles o no siguen una distribución lineal. No obstante, puesto que hay un número considerable de muestras, en algunos casos podría considerarse normalidad a través del Teorema del Límite Central (quizá únicamente en la variable *age*).

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Histograma vs. normal
multi.hist(x = df_train[,v_var_cuant], dcol = c("blue", "red"), dlty = c("dotted", "solid"))

# Gráfico Q-Q
par(mfrow = c(1, 4))
for (i in v_var_cuant){
  qqnorm(df_train[,i], main=colnames(df)[i], col = "red")
  qqline(df_train[,i])
}
```

### Homocedasticidad

Puesto que los datos no siguen una distribución normal, se aplicará el test de Fligner-Killeen como alternativa no paramétrica para evaluar la igual de varianzas basada también en el contraste de hipótesis. La hipótesis nula asume igualdad de varianzas en los diferentes grupos de datos (homocedasticidad), por lo que p-valores inferiores al nivel de significancia indicarán heterocedasticidad.


```{r echo=TRUE, message=FALSE, warning=FALSE}

fligner.test(Age ~ SibSp, data = df_train)
fligner.test(Age ~ Parch, data = df_train)
fligner.test(Age ~ Fare, data = df_train)
fligner.test(SibSp ~ Parch, data = df_train)
fligner.test(SibSp ~ Fare, data = df_train)
fligner.test(Parch ~ Fare, data = df_train)
```

Se verifica que todas las variables dos a dos cumplen heterocedasticidad al tener todas un variable de p-value inferior al nivel de significancia (0.05).

### Correlación

A continuación, se procede a analizar la correlación entre las variables, para lo que se hace necesario normalizar las variables. En este apartado, considerando que la variable *age* podría tender a la normalidad, se procede a inferir los valores NA por la mediana (más robusta que la media).

En cualquier caso, se aplica el test de correlación de Spearman, especialmente para casos que no cumplen normalidad.

*Nota*: Se puede comprobar que la inferencia no afecta prácticamente a las medidas de tendencia central (por su normalidad) y las de dispersión se ven ligeramente reducidas. No obstante, sería relevante probar otros métodos de inferencia como las regresiones, modelos bayesianos o los árboles de decisión (kNN, missForest, etc.), entre otros; y comprobar como afecta a los estadísticos y a su vez a los diferentes modelos a aplicar.

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Inferencia de valores nulos en Age 
df_train$Age <- replace(df_train$Age, which(is.na(df_train$Age)), median(df_train$Age, na.rm=TRUE))

# Normalización
df_norm <- as.data.frame(scale(df_train[,v_var_cuant]))

# Matriz de correlación y p-value
rcorr(as.matrix(df_norm), type = "spearman")

# Visualización de correlación y los diagramas de dispersión
corrplot.mixed(cor(df_norm, method = "spearman"))
pairs.panels(x = df_norm, ellipses = FALSE, lm = TRUE, method = "spearman", hist.col = "cadetblue1")
```

Se observa que no existen fuertes correlaciones entre las variables cuantitativas (si se establece como umbral |0.5|). Además, se comprueba que son estadísticamente significativos y, por tanto, improbable que este resultado se haya debido al azar.


### Selección de datos

Puesto que la variable clasificadora es *Survived* y la cual determina la persona sobrevivió o no, se va a analizar a través de un modelo logístico la influencia de cada una de las variables en combinación de otras de forma que se pueda observar cuáles son las más significativas y a partir de las cuales se determinará realizar el análisis de datos:

```{r echo=TRUE, message=FALSE, warning=FALSE}
attach(df_train)

set.seed(1234)

summary(glm(Survived~., df_train, family=binomial(link=logit)))
```

Tal y como se puede observar, las variables más significativas son *Age, Pclass y Sex*. Por tanto, será sobre estas variables sobre las que se hará el análisis de datos.


### Regresión

A continuación, se procede a analizar la relación existente entre algunas variables y vercómo afectan estas con respecto a la variable clasificadora *Survived* (variable dicotómica). Para ello, se aplicarán modelos de regresión logística. 

Por ejemplo, vamos a ver cómo afecta el sexo, la edad y la clase del billete. De esta forma, se infiere un modelo considerando la variable *Survived* como variable dependiente y los atributos *PClass, Sex y Age *como variables regresoras o independientes en combinación unas de otras.

```{r echo=TRUE, message=FALSE, warning=FALSE}

set.seed(1234)

# Generación del modelo
glm1 <- glm(Survived~Pclass, family=binomial(link=logit))
glm2 <- glm(Survived~Pclass+Sex, family=binomial(link=logit))
glm3 <- glm(Survived~Pclass+Sex+Age, family=binomial(link=logit))

# Tabla de coeficientes IC
tabla.coeficientes <- data.frame(c(1:3), c(glm1$aic,glm2$aic,glm3$aic))      
colnames(tabla.coeficientes) <- c("Modelo", "AIC")
tabla.coeficientes
```

El índice AIC (Akaike Information Criterion) relaciona la bondad junto con la complejidad del modelo y será de utilidad de cara a comparar con otros modelos (cuanto menor sea el índice, mejor se comportará el modelo). Tal y como se puede observar, a mayor número de variables mejor comportamiento del modelo. Por tanto, se parte del último modelo (glm3) para continuar con el análisis:

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(glm3)

# Odds Ratio
exp(coefficients(glm3))
```

Según los resultados, se observa que todas las variables son altamente significativas (Pr(>|z|) < 0.05). Puesto que hay índices de OR inferiores a uno, se hace necesario calcular su inversa para poder valorar la contribución relativa de las distintas variables en el modelo. Por tanto:

```{r echo=TRUE, message=FALSE, warning=FALSE}
1/exp(coefficients(glm3))[2:5]
```

De esta forma, se observa que la variable que más impacto genera en este modelo sobre la variable independiente *Survived* es la variable *Sex* (un indícativo adicional de que era uno de los principales criterios para abordar el salvamento y que, por tanto, tuvo que ver en el tipo de personas que lograron salvarse).

Si interpretamos los coeficientes parciales de la variable *Sex* (-2.611494) se observa que es negativo. Esto quiere decir que la probabilidad de que una persona sea sexo masculino influye indirectamente en que esta misma persona sea salvada; o lo que es lo mismo, reduce la probabilidad de ser salvada. Lo mismo sucede con ser pasajeros de 2º y 3º clase. Esto verifica en parte las suposiciones de que se priorizaba los miembros de 1º clase, así como las mujeres y los niños.

Sin embargo, según este modelo, se observa que la variable *Age* posee un OR próximo a 1; esto es un indicativo que prácticamente no existe asociación entre la variable respuesta y la covariable en dicho modelo. Esto puede verse en la siguiente visualización:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = df_train, mapping=aes(x = Age, y = Survived, color=Survived)) +
   geom_boxplot() +
   geom_jitter(width = 0.1) +
   theme_bw() + theme(legend.position = "none")
```

No obstante, si se realiza un análisis comparativo de las variables en términos absolutos y de frencuencia, se observa que la proporción de niños salvados es más elevada que en el resto de edades:


```{r echo=TRUE, message=FALSE, warning=FALSE}

g1 <- ggplot(data = df_original[!(is.na(df_original$Age)),],aes(x=Age,fill=Survived))+geom_histogram(binwidth =3)
g2 <- ggplot(data = df_original[!(is.na(df_original$Age)),],aes(x=Age,fill=Survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")

grid.arrange(g1, g2,  nrow = 1)
```

***Nota***: Este es otro de los puntos donde se hace retrospectiva, ver cómo afecta al modelo y su calidad la inferencia de los valores nulos y el tratamiento de outliers.

### Árbol de decisión

El modelo de análisis a aplicar se basa en el algoritmo C5.0, una evolución del C4.5 y el ID3, el cual utiliza una pospoda por promoción automática. Este modelo permite sólo variables de salida categórica, mientras que las de entrada pueden ser de naturaleza continua o categórica. Este modelo se obtiene a partir de la función C5.0() y permite su conversión a reglas. Se aplica sobre las mismas variables anteriormente evaluadas:

```{r echo=TRUE, message=FALSE, warning=FALSE}

set.seed(1234)

# Modelo C5.0 en árbol
model_C50t <- C5.0(Survived~Age+Pclass+Sex , df_train)

# Detalle del modelo
summary(model_C50t)
```
Tal y como se puede observar este modelo consigue una tasa de error de 19%%. La variable de más peso en este tipo modelo es *Sex*, al igual que sucedía en el caso anterior.

A continuación, generamos el conjunto de reglas y se visualiza el árbol generado para su posterior análisis:

```{r echo=TRUE, message=FALSE, warning=FALSE}

set.seed(1234)

# Modelo C5.0 en árbol
model_C50r <- C5.0(Survived~Age+Pclass+Sex , df_train,, rules = TRUE)

# Detalle del modelo
summary(model_C50r)

# Visualización
plot(model_C50t)
```


Analizando las reglas, se puede observar que un pasajero de menos de 9 años, que viajaba en 1ªo 2ª clase, de sexo masculino, se salvaba con 92,3% de validez. También resulta interesante ver que una persona con edad superior a 38 años y que viajase en 3ª clase no sobreviviría con un 90,6% de validez.

Si se observa el gráfico del árbol, se pude observar que un pasajero de sexo femenino que viajaba en 1ª o 2ª clase tenía una alta probabilidad de sobrevivir.


******
# Conclusiones
******